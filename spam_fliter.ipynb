{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Spam Filter with the Naive Bayes"
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will be building a SMS message spam filter for this project. We will be using a premade dataset for this purpose. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the The UCI Machine Learning Repository. You can also download the dataset directly from this link. The data collection process is described in more details on this page, where you can also find some of the authors' papers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploring the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "\n",
    "SMS_data = pd.read_csv('SMSSpamCollection', header=None, sep='\\t', names=['Label', 'SMS'])"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(SMS_data.describe)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bound method DataFrame.describe of      Label                                                SMS\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6      ham  Even my brother is not like to speak with me. ...\n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8     spam  WINNER!! As a valued network customer you have...\n",
      "9     spam  Had your mobile 11 months or more? U R entitle...\n",
      "10     ham  I'm gonna be home soon and i don't want to tal...\n",
      "11    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12    spam  URGENT! You have won a 1 week FREE membership ...\n",
      "13     ham  I've been searching for the right words to tha...\n",
      "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
      "16     ham                         Oh k...i'm watching here:)\n",
      "17     ham  Eh u remember how 2 spell his name... Yes i di...\n",
      "18     ham  Fine if thats the way u feel. Thats the way ...\n",
      "19    spam  England v Macedonia - dont miss the goals/team...\n",
      "20     ham          Is that seriously how you spell his name?\n",
      "21     ham    I‘m going to try for 2 months ha ha only joking\n",
      "22     ham  So ü pay first lar... Then when is da stock co...\n",
      "23     ham  Aft i finish my lunch then i go str down lor. ...\n",
      "24     ham  Ffffffffff. Alright no way I can meet up with ...\n",
      "25     ham  Just forced myself to eat a slice. I'm really ...\n",
      "26     ham                     Lol your always so convincing.\n",
      "27     ham  Did you catch the bus ? Are you frying an egg ...\n",
      "28     ham  I'm back &amp; we're packing the car now, I'll...\n",
      "29     ham  Ahhh. Work. I vaguely remember that! What does...\n",
      "...    ...                                                ...\n",
      "5542   ham           Armand says get your ass over to epsilon\n",
      "5543   ham             U still havent got urself a jacket ah?\n",
      "5544   ham  I'm taking derek &amp; taylor to walmart, if I...\n",
      "5545   ham      Hi its in durban are you still on this number\n",
      "5546   ham         Ic. There are a lotta childporn cars then.\n",
      "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5548   ham                 No, I was trying it all weekend ;V\n",
      "5549   ham  You know, wot people wear. T shirts, jumpers, ...\n",
      "5550   ham        Cool, what time you think you can get here?\n",
      "5551   ham  Wen did you get so spiritual and deep. That's ...\n",
      "5552   ham  Have a safe trip to Nigeria. Wish you happines...\n",
      "5553   ham                        Hahaha..use your brain dear\n",
      "5554   ham  Well keep in mind I've only got enough gas for...\n",
      "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
      "5556   ham  Yes i have. So that's why u texted. Pshew...mi...\n",
      "5557   ham  No. I meant the calculation is the same. That ...\n",
      "5558   ham                             Sorry, I'll call later\n",
      "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...\n",
      "5560   ham                  Anything lor. Juz both of us lor.\n",
      "5561   ham  Get me out of this dump heap. My mom decided t...\n",
      "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
      "5563   ham                                Ard 6 like dat lor.\n",
      "5564   ham  Why don't you wait 'til at least wednesday to ...\n",
      "5565   ham                                       Huh y lei...\n",
      "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham               Will ü b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]>\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "SMS_data['Label'].value_counts()\n",
    "# We find that 747 of the messages are spam\n",
    "\n",
    "print(747/5572)\n",
    "# Percentage of messages that are spam"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13406317300789664\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see from a quick look at the dataset, we have 5572 specific text messages, 747 of which are spam. This is a percentage of roughly 13.4%. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Test Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're going to keep 80% of our dataset for training, and 20% for testing (we want to train the algorithm on as much data as possible, but we also want to have enough test data). The dataset has 5,572 messages, which means that:\n",
    "\n",
    "    The training set will have 4,458 messages (about 80% of the dataset).\n",
    "    The test set will have 1,114 messages (about 20% of the dataset).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this project, our goal is to create a spam filter that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "SMS_data_randomized = SMS_data.sample(frac=1, random_state=1)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "SMS_data_training = SMS_data_randomized[0:4458]\n",
    "# Training data will be roughly 80% of the data\n",
    "\n",
    "SMS_data_testing = SMS_data_randomized[4458:]\n",
    "# Testing data will be roughly 20$ of the data\n",
    "\n",
    "SMS_data_training['Label'].value_counts()\n",
    "print(600/4458)\n",
    "# The percentage of spam in the sample is nearly the same of the entire dataset\n",
    "\n",
    "SMS_data_testing['Label'].value_counts()\n",
    "print(147/1114)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13458950201884254\n",
      "0.1319569120287253\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Resetting the index labels\n",
    "SMS_data_training.reset_index(inplace=True)\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "SMS_data_testing.reset_index(inplace=True)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After randomizing and splitting up the dataset, we can see our new randomized samples for training and testing both come out to roughly 13$ spam. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Letter Case and Punctuation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to more easily work with the data and make the necessary probability calculations, we'll want to create new columns based on the vocabulary of the SMS messages. Before we can do this though, we need to strip out puncutation, and conver all words to lower case. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "SMS_data_training.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS\n",
       "0   1078   ham                       Yep, by the pretty sculpture\n",
       "1   4028   ham      Yes, princess. Are you going to make me moan?\n",
       "2    958   ham                         Welp apparently he retired\n",
       "3   4642   ham                                            Havent.\n",
       "4   4674   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "SMS_data_training['SMS'] = SMS_data_training['SMS'].str.replace('\\W', ' ')\n",
    "SMS_data_training['SMS'] = SMS_data_training['SMS'].str.lower()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "SMS_data_training.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS\n",
       "0   1078   ham                       yep  by the pretty sculpture\n",
       "1   4028   ham      yes  princess  are you going to make me moan \n",
       "2    958   ham                         welp apparently he retired\n",
       "3   4642   ham                                            havent \n",
       "4   4674   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing the `head` output for before and after our replace and lower fucntion use, we can see we have simplified the SMS messages sucssefully. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the Vocabulary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we need to get a list of all the words across the SMS messages. This is the next step before we can transform our data set to display the vocabulary as column headers with cells denoting their frequency, message to message. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "SMS_data_training['SMS'] = SMS_data_training['SMS'].str.split()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "SMS_data_training.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS\n",
       "0   1078   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   4028   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2    958   ham                    [welp, apparently, he, retired]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Initializing list and looping to add each SMS message word to it\n",
    "vocabulary = []\n",
    "for sms in SMS_data_training['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        "
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "vocabulary = set(vocabulary) # Remove duplicates"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "vocabulary = list(vocabulary)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "len(vocabulary)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It appears we have 7,783 unique words across all of the SMS messages in our training dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Final Training Set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now create a dictionary for each message that contains the words and their frequencies for each message. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(SMS_data_training['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(SMS_data_training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Turning our dicitonary into a DataFrame\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "training_set_clean = pd.concat([SMS_data_training, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4028</td>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4642</td>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS  0  00  000  \\\n",
       "0   1078   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   4028   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2    958   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   4642   ham                                           [havent]  0   0    0   \n",
       "4   4674   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334 ...  zindgi  zoe  zogtorius  zouk  \\\n",
       "0       0             0     0            0 ...       0    0          0     0   \n",
       "1       0             0     0            0 ...       0    0          0     0   \n",
       "2       0             0     0            0 ...       0    0          0     0   \n",
       "3       0             0     0            0 ...       0    0          0     0   \n",
       "4       0             0     0            0 ...       0    0          0     0   \n",
       "\n",
       "   zyada  é  ú1  ü  〨ud  鈥  \n",
       "0      0  0   0  0    0  0  \n",
       "1      0  0   0  0    0  0  \n",
       "2      0  0   0  0    0  0  \n",
       "3      0  0   0  0    0  0  \n",
       "4      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7786 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Constants"
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will need to calculate some constants in order to complete our spam filter. These initial values are:\n",
    "\n",
    "- P(Spam) and P(Ham)\n",
    "- Nspam, Nham, and Nvocabulary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Separating out the 'Spam' and 'Ham' messages\n",
    "spam_messages = training_set_clean[training_set_clean[\"Label\"] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean[\"Label\"] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages)/len(training_set_clean)\n",
    "p_ham = len(ham_messages)/len(training_set_clean)\n",
    "\n",
    "# Nspam, Nham, Nvocabulary\n",
    "n_spam = spam_messages['SMS'].apply(len).sum()\n",
    "n_ham = ham_messages['SMS'].apply(len).sum()\n",
    "\n",
    "n_vocabulary = len(vocabulary)\n",
    "alpha = 1\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating Parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to calculate the parameters, which in this instance would be probability of a word given spam, and the probability of a word given ham, for each word within our vocabulary. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Initialize dictionaries for 'spam' and 'ham'\n",
    "spam_parameters = {unique_word: 0 for unique_word in vocabulary}\n",
    "ham_parameters = {unique_word: 0 for unique_word in vocabulary}\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "for word in vocabulary:\n",
    "    # Spam Parameter\n",
    "    n_word_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha)/(n_spam + (alpha * n_vocabulary))\n",
    "    spam_parameters[word] = p_word_given_spam\n",
    "    \n",
    "    # Ham Parameter\n",
    "    n_word_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha)/(n_ham + (alpha * n_vocabulary))\n",
    "    ham_parameters[word] = p_word_given_ham\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classifying a New Message"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter."
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "       \n",
    "    # This is where we calculate:\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "            \n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "    # ---   \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Test messages for our classify() function\n",
    "\n",
    "spam_test = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "ham_test = \"Sounds good, Tom, then see u there\"\n",
    "\n",
    "classify(spam_test)\n",
    "classify(ham_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing with one message that is obviously spam, and one that is obviously ham, we can see that our `classify()` function has worked successfully. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Measuring the Spam Filter's Accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " We'll now try to determine how well the spam filter does on our test set of 1,114 messages.\n",
    "\n",
    "The algorithm will output a classification label for every message in our test set, which we'll be able to compare with the actual label (given by a human). Note that, in training, our algorithm didn't see these 1,114 messages, so every message in the test set is practically new from the perspective of the algorithm. \n",
    "\n",
    "Below we will construct a repurposed classify function, one that can evaluate the test set. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "\n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "SMS_data_testing['predicted'] = SMS_data_testing['SMS'].apply(classify_test_set)\n",
    "SMS_data_testing.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/dataquest/system/env/python3/lib/python3.4/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2131</td>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3418</td>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1538</td>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5393</td>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Label                                                SMS predicted\n",
       "0   2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2   3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   1538   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   5393   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have a new function to classify the test set, we can now see how accurate our classify function is."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "correct = 0\n",
    "total = 1114\n",
    "    \n",
    "for row in SMS_data_testing.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy of the classify function is 98%, which is very good for classifying 1114 previously unseen messages. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}